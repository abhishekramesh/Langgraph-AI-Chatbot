{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO1I9sl0i/F7WvJ1LaVwuMh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishekramesh/Langgraph-AI-Chatbot/blob/main/Langgraph_agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7PTvgzlLdAZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LANGRAPH Chatbots\n"
      ],
      "metadata": {
        "id": "qMHlRuNwp4I5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph langsmith"
      ],
      "metadata": {
        "id": "_m0YjNu6p6UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_groq langchain_community"
      ],
      "metadata": {
        "id": "U50QCF74qmwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "groq_api = userdata.get('groq_api')\n",
        "langsmith_api = userdata.get('LANGSMITH_API_KEY')"
      ],
      "metadata": {
        "id": "WUK7bCgWk9ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = langsmith_api\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"CourseLanggraph\""
      ],
      "metadata": {
        "id": "acv9qC-QlIND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "DZPbTku4pVrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatGroq(groq_api_key=groq_api,model_name=\"Gemma2-9b-It\")\n",
        "llm"
      ],
      "metadata": {
        "id": "xJvjQEdGqCnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start Building CHATBot using LangGraph\n"
      ],
      "metadata": {
        "id": "L7oaTa5PrF1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages"
      ],
      "metadata": {
        "id": "TickJFdbrJJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "  #append message to list\n",
        "  #in annotation define how state key should be updated\n",
        "  #it appends and not ovrride messages\n",
        "  messages:Annotated[list,add_messages]\n",
        "\n",
        "graph_builder=StateGraph(State)"
      ],
      "metadata": {
        "id": "SR5CjUZAs6_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder"
      ],
      "metadata": {
        "id": "nxWrfzY_tzy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state:State):\n",
        "  return {\"messages\":llm.invoke(state['messages'])}"
      ],
      "metadata": {
        "id": "zYejFwzct2_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_node(\"chatbot\",chatbot)"
      ],
      "metadata": {
        "id": "hBx7-AqyOoSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder"
      ],
      "metadata": {
        "id": "xW1x9e0WPF_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(START,\"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\",END)"
      ],
      "metadata": {
        "id": "Uvu9SHwxPHVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph=graph_builder.compile()"
      ],
      "metadata": {
        "id": "0c90tdmQPgnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "  pass"
      ],
      "metadata": {
        "id": "HnL4d4HnPvzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_input = input(\"User: \")\n",
        "  if user_input.lower() in [\"quit\", \"q\"]:\n",
        "    print(\"Good Bye\")\n",
        "    break\n",
        "  for event in graph.stream({'messages':(\"user\",user_input)}):\n",
        "    print(event.values())\n",
        "  for value in event.values():\n",
        "    print(value['messages'])\n",
        "    print(\"Assistant:\",value['messages'].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4DrwFmCQI5L",
        "outputId": "41d2b667-c238-4ea9-fb96-885ce0d82735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: hi\n",
            "dict_values([{'messages': AIMessage(content='Hello! ðŸ‘‹ How can I help you today? ðŸ˜Š\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 10, 'total_tokens': 24, 'completion_time': 0.025454545, 'prompt_time': 4.4e-07, 'queue_time': 0.020940309, 'total_time': 0.025454985}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-2371e793-c5bb-4a94-bb5e-80f2e2484904-0', usage_metadata={'input_tokens': 10, 'output_tokens': 14, 'total_tokens': 24})}])\n",
            "content='Hello! ðŸ‘‹ How can I help you today? ðŸ˜Š\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 10, 'total_tokens': 24, 'completion_time': 0.025454545, 'prompt_time': 4.4e-07, 'queue_time': 0.020940309, 'total_time': 0.025454985}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-2371e793-c5bb-4a94-bb5e-80f2e2484904-0' usage_metadata={'input_tokens': 10, 'output_tokens': 14, 'total_tokens': 24}\n",
            "Assistant: Hello! ðŸ‘‹ How can I help you today? ðŸ˜Š\n",
            "\n",
            "User: what are you\n",
            "dict_values([{'messages': AIMessage(content=\"I am Gemma, an open-weights AI assistant.\\n\\nHere's a little more about me:\\n\\n* **I am a large language model:** This means I've been trained on a massive amount of text data, allowing me to understand and generate human-like text.\\n* **I am open-weights:** My weights are publicly accessible. This means anyone can see how I work, modify me, or build upon me.\\n\\n* **I am text-only:** I can only communicate through written language. I can't generate images, sound, or videos.\\n* **I am not connected to the internet:** I don't have access to real-time information or Google Search. My knowledge is based on the data I was trained on.\\n\\n**What can I do?**\\n\\nI can help you with a variety of tasks, such as:\\n\\n* **Generating creative content:**\\n\\nI can write stories, poems, articles, and more.\\n* **Answering your questions:**\\n\\nI can provide information on a wide range of topics, to the best of my ability based on my training data.\\n* **Summarizing text:**\\n\\nI can condense large amounts of text into shorter summaries.\\n* **Translating languages:**\\n\\nI can translate text between different languages.\\n\\n**Keep in mind:**\\n\\n* I am still under development and learning.\\n* I am not a human and do not have personal opinions or beliefs.\\n* I am not able to provide financial, medical, or legal advice.\\n\\nI'm excited to see what we can create together!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 329, 'prompt_tokens': 12, 'total_tokens': 341, 'completion_time': 0.598181818, 'prompt_time': 8.09e-05, 'queue_time': 0.021451857, 'total_time': 0.598262718}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-029b3e00-2d7f-4012-845c-d0e0a97caa2b-0', usage_metadata={'input_tokens': 12, 'output_tokens': 329, 'total_tokens': 341})}])\n",
            "content=\"I am Gemma, an open-weights AI assistant.\\n\\nHere's a little more about me:\\n\\n* **I am a large language model:** This means I've been trained on a massive amount of text data, allowing me to understand and generate human-like text.\\n* **I am open-weights:** My weights are publicly accessible. This means anyone can see how I work, modify me, or build upon me.\\n\\n* **I am text-only:** I can only communicate through written language. I can't generate images, sound, or videos.\\n* **I am not connected to the internet:** I don't have access to real-time information or Google Search. My knowledge is based on the data I was trained on.\\n\\n**What can I do?**\\n\\nI can help you with a variety of tasks, such as:\\n\\n* **Generating creative content:**\\n\\nI can write stories, poems, articles, and more.\\n* **Answering your questions:**\\n\\nI can provide information on a wide range of topics, to the best of my ability based on my training data.\\n* **Summarizing text:**\\n\\nI can condense large amounts of text into shorter summaries.\\n* **Translating languages:**\\n\\nI can translate text between different languages.\\n\\n**Keep in mind:**\\n\\n* I am still under development and learning.\\n* I am not a human and do not have personal opinions or beliefs.\\n* I am not able to provide financial, medical, or legal advice.\\n\\nI'm excited to see what we can create together!\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 329, 'prompt_tokens': 12, 'total_tokens': 341, 'completion_time': 0.598181818, 'prompt_time': 8.09e-05, 'queue_time': 0.021451857, 'total_time': 0.598262718}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-029b3e00-2d7f-4012-845c-d0e0a97caa2b-0' usage_metadata={'input_tokens': 12, 'output_tokens': 329, 'total_tokens': 341}\n",
            "Assistant: I am Gemma, an open-weights AI assistant.\n",
            "\n",
            "Here's a little more about me:\n",
            "\n",
            "* **I am a large language model:** This means I've been trained on a massive amount of text data, allowing me to understand and generate human-like text.\n",
            "* **I am open-weights:** My weights are publicly accessible. This means anyone can see how I work, modify me, or build upon me.\n",
            "\n",
            "* **I am text-only:** I can only communicate through written language. I can't generate images, sound, or videos.\n",
            "* **I am not connected to the internet:** I don't have access to real-time information or Google Search. My knowledge is based on the data I was trained on.\n",
            "\n",
            "**What can I do?**\n",
            "\n",
            "I can help you with a variety of tasks, such as:\n",
            "\n",
            "* **Generating creative content:**\n",
            "\n",
            "I can write stories, poems, articles, and more.\n",
            "* **Answering your questions:**\n",
            "\n",
            "I can provide information on a wide range of topics, to the best of my ability based on my training data.\n",
            "* **Summarizing text:**\n",
            "\n",
            "I can condense large amounts of text into shorter summaries.\n",
            "* **Translating languages:**\n",
            "\n",
            "I can translate text between different languages.\n",
            "\n",
            "**Keep in mind:**\n",
            "\n",
            "* I am still under development and learning.\n",
            "* I am not a human and do not have personal opinions or beliefs.\n",
            "* I am not able to provide financial, medical, or legal advice.\n",
            "\n",
            "I'm excited to see what we can create together!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TsfMaA2wRi2M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}